<!DOCTYPE html>
<html><head>
         <meta charset="utf-8">
		 <meta name="viewport" content="width=device.width, initial-scale=1">
		 
		 <title> rubz.dev </title>
		 
		 <link rel="preconnect" href="https://fonts.googleapis.com">
		 <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		 <link href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@500&display=swap" rel="stylesheet">
		 
		  
		 
		 
		 
		 
		 <link rel="stylesheet" href="/css/main.min.9e4f848ac6530b52e56b52c0f436a82b81e39d1221e44c8eb760e16f06c4036a.css" integrity="sha256-nk+EisZTC1Lla1LA9DaoK4HjnRIh5EyOt2DhbwbEA2o=">
		 

		
  </head>

<body>
	<div class="main"><nav class="bg-black border-b-2 fixed inset-x-0 top-0">
	<div class="px-8 mx-10-xl sm:mx-10">
		<div class="flex justify-between">
			<div class="flex space-x-4 m-2">
				<a href="/" class="flex items-center">
					<svg class=" text-white h-6 w-6 md:h-6 md:w-6 mr-2" xmlns="http://www.w3.org/2000/svg"
						class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
						<path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
							d="M8 9l3 3-3 3m5 0h3M5 20h14a2 2 0 002-2V6a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z" />
					</svg>
					<span class="text-white font-bold"> rubz.dev </span>
				</a>
			</div>
			<div class="hidden md:flex  space-x-4 m-2 text-white font-semibold">

				<a class="hover:bg-white hover:text-black" href="/about">about</a>
				<a class="hover:bg-white hover:text-black" href="/posts">posts</a>
			</div>

			<div class="md:hidden text-white flex ">
				<button class="mobile-menu-btn">

					<svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24"
						stroke="currentColor">
						<path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7" />
					</svg>

				</button>
			</div>


		</div>
		<div class="mobile-menu hidden text-white flex-col font-bold">
			<a class="block py-4  hover:text-gray-500 " href="/about">about</a>
			<a class="block py-4  hover:text-gray-500" href="/posts">posts</a>

		</div>
		<div>

			<script>
				const btn = document.querySelector('button.mobile-menu-btn');
				const menu = document.querySelector('.mobile-menu')


				btn.addEventListener('click', () => {
					menu.classList.toggle('hidden');
				});
			</script>
</nav><main>
<div class="flex flex-row  min-h-screen  justify-center">


	<div class="flex flex-col w-full justify-center items-center">

		<header class="text-black pt-16 pb-12  p-2 w-128">
			<div class="py-2">
				<span class="bg-black md:text-2xl text-white font-semibold p-1">
					August 23,2020</span>

			</div>
			<h1 class="text-2xl md:text-6xl font-bold"> Creating Spotify Playlist with Machine Learning </h1>
			<div class="flex flex-row pt-4">

				<div>
					
					<a class="p-1 text-xs mr-1 md:text-xl bg-black font-bold text-white" href="/tags/programming">programming</a>
					
					<a class="p-1 text-xs mr-1 md:text-xl bg-black font-bold text-white" href="/tags/python">python</a>
					
					<a class="p-1 text-xs mr-1 md:text-xl bg-black font-bold text-white" href="/tags/clustering">clustering</a>
					
				</div>

				<p class="p-1 mr -1 text-xs mr-4 md:text-xl font-bold">
					Reading time: 8m
				</p>
			</div>

		</header>

		<div class="prose lg:prose-xl  md:p-4 w-full p-3">
			<h2 id="have-you-ever-wondered-how-companies-or-apps-do-to-recommend-moderately-successful-content-to-what-we-are-consuming">Have you ever wondered how companies or Apps do to recommend moderately successful content to what we are consuming?</h2>
<p><img src="https://miro.medium.com/max/681/1*-pEHTlOdX_7mlvzk3UUHPQ.png" alt="img"></p>
<p>When I asked myself this question I thought that obviously they must have a lot of information about their products such as Mercado Libre or Amazon: Product categories, weight, our purchase and search history, which product is usually bought together with another and so we can continue thinking of variables that could help recommend a product to a potential buyer.</p>
<p>But then I changed the focus of my thinking towards more intangible products such as music. Although music could be acquired in a tangible way in the form of CDs, we all know that today the music business does not work that way if not digitally. Several companies have emerged from this new business model and one of them is Spotify, which I think does not need to present it due to its wide popularity. Now going back to my previous thought, Spotify not only has our searches, playlists and most listened songs to be able to recommend new music to us, but it can also afford to perform an analysis of the music to find more features that lead to a better recommendation.</p>
<p><img src="https://miro.medium.com/max/1400/1*8-BtIdanLJEUtSKkoqSmAw.png" alt="img"></p>
<p>Researching their official API, I found that they offer a request in which one can get the audio features of a song. There are several features that we obtain and they range from how instrumental the song is, how danceable, how energetic and among many more. I recommend that you enter yourself and see the large number of options that the API offers.</p>
<hr>
<p>Having found this functionality I came up with the following: use an unsupervised algorithm so that with all my lists, I generate different clusters according to the features of the API.</p>
<h2 id="first-step-create-keys-to-access-the-api">First Step: Create Keys to access the API</h2>
<p>We start first with everything that would be the configuration to use the API. We go to the official website of the API and go to the dashboard section where it will ask us to register as developers. They register and right there we go to the option “Create an App”</p>
<p>![img][https://miro.medium.com/max/894/1*Prkvi8VQTZL9Jh48mmYgAg.png]</p>
<p>It will ask us for a name, a description and that we accept the terms and conditions.</p>
<p><img src="https://miro.medium.com/max/980/1*JMOXFdyrHY88psBtWcRSnA.png" alt="img"></p>
<p>Once the App is created, it will redirect us to its Dashboard where we can see the API credentials, which is what matters most to us. We copy them and within our repository we create a python type file where we are going to paste them.</p>
<p><img src="https://miro.medium.com/max/1400/1*pcHi5bL002r6QzAi8ARh9g.png" alt="img"></p>
<p>The reason why we leave them outside the notebook is to be able to share it without the risk of someone using our credentials for something malicious.</p>
<p><em><strong>Important note:</strong></em> We are going to be using the Python Spotipy library that facilitates the handling of the API.</p>
<p>We then start by importing the libraries and loading the credentials into the notebook.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> spotipy
<span style="color:#f92672">import</span> credentials
<span style="color:#f92672">from</span> tqdm <span style="color:#f92672">import</span> tqdm_notebook <span style="color:#66d9ef">as</span> tqdm
<span style="color:#f92672">from</span> spotipy.oauth2 <span style="color:#f92672">import</span> SpotifyClientCredentials, SpotifyOAuth
<span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
client_credentials_manager <span style="color:#f92672">=</span> SpotifyClientCredentials(client_id<span style="color:#f92672">=</span>credentials<span style="color:#f92672">.</span>client_id,
                                                      client_secret<span style="color:#f92672">=</span>credentials<span style="color:#f92672">.</span>client_secret)
sp <span style="color:#f92672">=</span> spotipy<span style="color:#f92672">.</span>Spotify(client_credentials_manager<span style="color:#f92672">=</span>client_credentials_manager)

</code></pre></div><hr>
<h2 id="second-step-extract-the-data-from-the-api-and-process-it">Second Step: Extract the data from the API and process it:</h2>
<p>Now that we have the credentials loaded in the jupyter notebook, we can start making basic queries to see the API responses.
I first thought that in order to extract all my songs I would have to be able to extract all my playlists. The get_user_playlist() function allows us to fetch all our playlists, with many specifications for each one.</p>
<p><em><strong>Note:</strong></em> As you can see, I am going to show only the first result because if I paste the entire result, the post would take forever.</p>
<p><code>sp.user_playlists('11101312700')['items'][0]</code></p>
<p><img src="https://miro.medium.com/max/1400/1*yNhW5Sugcrm8wO8t38VpqQ.png" alt="img"></p>
<p>As we can see, the API provides us with the details of each playlist that my user has, the most important data we need is the id to later use it in conjunction with the get_playlists_tracks() function</p>
<p><code>sp.playlist_tracks('39ATQymddYN7NyYh9o1wJt')['items'][0]</code></p>
<p><img src="https://miro.medium.com/max/1400/1*7WV-PrCVdfcAhbvKlkvx3w.png" alt="img"></p>
<p>As a result, it returns all the tracks that the list has with all the information of each one. The most important thing would be missing&hellip; the audio features that I mentioned so much before and to get each of them there is a function called audio_features()</p>
<p><code>sp.audio_features('2kmX8QNMLg72Vy9Ux6mdmi')</code></p>
<p><img src="https://miro.medium.com/max/1242/1*1oi4zsq1mff56UjjeJWmvg.png" alt="img"></p>
<p>Using these three functions, I created two functions that allow me to extract all the songs from my playlists and also concatenate the audio features of each one.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_all_data</span>(user_id):
    
    <span style="color:#75715e">#get all the playlist id&#39;s</span>
    
    track_list <span style="color:#f92672">=</span> []
    sname_list <span style="color:#f92672">=</span> []
    artist_list <span style="color:#f92672">=</span> []
    audio_ft <span style="color:#f92672">=</span> []
    
        
    <span style="color:#66d9ef">for</span> playlist <span style="color:#f92672">in</span> tqdm(sp<span style="color:#f92672">.</span>user_playlists(user_id)[<span style="color:#e6db74">&#39;items&#39;</span>]):
            <span style="color:#66d9ef">for</span> idx,track <span style="color:#f92672">in</span> enumerate(sp<span style="color:#f92672">.</span>playlist_tracks(playlist[<span style="color:#e6db74">&#39;id&#39;</span>])[<span style="color:#e6db74">&#39;items&#39;</span>]):
                <span style="color:#66d9ef">if</span> track[<span style="color:#e6db74">&#39;track&#39;</span>][<span style="color:#e6db74">&#39;id&#39;</span>] <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
                    
                    track_list<span style="color:#f92672">.</span>append(track[<span style="color:#e6db74">&#39;track&#39;</span>][<span style="color:#e6db74">&#39;id&#39;</span>])
                    sname_list<span style="color:#f92672">.</span>append(track[<span style="color:#e6db74">&#39;track&#39;</span>][<span style="color:#e6db74">&#39;name&#39;</span>])
                    artist_list<span style="color:#f92672">.</span>append(track[<span style="color:#e6db74">&#39;track&#39;</span>][<span style="color:#e6db74">&#39;album&#39;</span>][<span style="color:#e6db74">&#39;artists&#39;</span>][<span style="color:#ae81ff">0</span>])
                    <span style="color:#75715e">#print(track[&#39;track&#39;][&#39;id&#39;])</span>
                    audio_ft<span style="color:#f92672">.</span>append(sp<span style="color:#f92672">.</span>audio_features(track[<span style="color:#e6db74">&#39;track&#39;</span>][<span style="color:#e6db74">&#39;id&#39;</span>])[<span style="color:#ae81ff">0</span>])
    
    df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame({<span style="color:#e6db74">&#39;name&#39;</span>: sname_list,
                       <span style="color:#e6db74">&#39;artist&#39;</span>: artist_list,
                       <span style="color:#e6db74">&#39;id&#39;</span>: track_list,
                       <span style="color:#e6db74">&#39;audio_ft&#39;</span>: audio_ft})
    
    <span style="color:#66d9ef">return</span> df

</code></pre></div><p>And in the following function it&rsquo;s just a slight transformation where we drop columns that are irrelevant to the analysis.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">transform_data</span>(df):
    
    df[<span style="color:#e6db74">&#39;artist&#39;</span>] <span style="color:#f92672">=</span> df[<span style="color:#e6db74">&#39;artist&#39;</span>]<span style="color:#f92672">.</span>apply(pd<span style="color:#f92672">.</span>Series)[<span style="color:#e6db74">&#39;name&#39;</span>]
    
    df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>concat([df,df[<span style="color:#e6db74">&#39;audio_ft&#39;</span>]<span style="color:#f92672">.</span>apply(pd<span style="color:#f92672">.</span>Series)], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
    
    df <span style="color:#f92672">=</span> df<span style="color:#f92672">.</span>drop(labels<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;time_signature&#39;</span>,<span style="color:#e6db74">&#39;duration_ms&#39;</span>,<span style="color:#e6db74">&#39;analysis_url&#39;</span>,<span style="color:#e6db74">&#39;track_href&#39;</span>,<span style="color:#e6db74">&#39;type&#39;</span>,<span style="color:#e6db74">&#39;audio_ft&#39;</span>], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
    
    <span style="color:#66d9ef">return</span> df


</code></pre></div><p>The result returns a Data Frame like this:</p>
<p><img src="https://miro.medium.com/max/1400/1*lpwJhlSKYSFhhV7t3NixGA.png" alt="img"></p>
<h2 id="third-step-data-clustering">Third Step: Data clustering:</h2>
<p>As a name at the beginning of the post, my idea was to use an unsupervised algorithm, but what is this?</p>
<p>Unsupervised learning is a technique used in machine learning where the algorithm feeds on our data set and the selected features to be able to cluster (divide into segments) according to some pattern found in the data. It feeds on “unlabeled” data, that is to say that in this case we are not trying to make the algorithm predict something, but to explore it by itself.</p>
<p><img src="https://miro.medium.com/max/1192/1*CSPfuqAIzu__DCNhuRw_DA.png" alt="img"></p>
<p>One of the best known unsupervised algorithms is K-means, which is the one we will use in this post. But before continuing with the algorithm process I want to explain the features that I chose for this clustering.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">features <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;danceability&#39;</span>,<span style="color:#e6db74">&#39;energy&#39;</span>,<span style="color:#e6db74">&#39;acousticness&#39;</span>
           ,<span style="color:#e6db74">&#39;instrumentalness&#39;</span>,<span style="color:#e6db74">&#39;valence&#39;</span>]
</code></pre></div><p><em><strong>danceability:</strong></em> Describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is less danceable and 1.0 is more danceable.</p>
<p><em><strong>energy:</strong></em> It is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual characteristics that contribute to this attribute include dynamic range, perceived loudness, timbre, onset frequency, and overall entropy.</p>
<p><em><strong>acousticness:</strong></em> A 0.0 to 1.0 confidence measure of whether the track is acoustic. 1.0 represents high confidence that the track is acoustic.</p>
<p><em><strong>instrumentalness:</strong></em> Predicts whether a track contains no vocals. The sounds “Ooh” and “aah” are treated as instrumental in this context. Rap tracks or spoken words are clearly &ldquo;vocals.&rdquo; The closer the instrumentality value is to 1.0, the greater the probability that the track contains no vocal content. Values ​​greater than 0.5 are intended to represent instrumental tracks, but the confidence increases as the value approaches 1.0.</p>
<p><em><strong>valence:</strong></em> A measure from 0.0 to 1.0 that describes the musical positivity conveyed by a track. Tracks with a high valence sound more positive (eg, happy, cheerful, euphoric), while tracks with a low valence sound more negative (eg, sad, depressed, angry).</p>
<p><em><strong>[Note: I recommend visiting the documentation where all the features are found with an even better explanation.]</strong></em>(<a href="https://developer.spotify.com/documentation/web-api/reference/tracks/get-several-audio-features/">https://developer.spotify.com/documentation/web-api/reference/tracks/get-several-audio-features/</a>)</p>
<p><img src="https://miro.medium.com/max/1400/1*qr_BMOhmLslbWL_MyCJvbA.png" alt="img"></p>
<p>Once the features have been explained, we are going to induce ourselves in the training of the algorithm. One drawback of k-means is that it will cluster the data into the number of clusters you want regardless of whether this number is not optimal for the problem.</p>
<p>One way to solve this and have an estimate of what our optimal amount would be is to use the Elbow Method. Which basically consists of iterating over a number of clusters, let&rsquo;s say from 1 to 10, and calculating the SSE (Sum of Squared Errors) in each one. Looking at the visualization of this iteration we should choose the number of clusters that has the smallest SSE.</p>
<p><img src="https://miro.medium.com/max/790/1*xBrHScNV7wimsOPgg1L8Dg.png" alt="img"></p>
<p>In our case, we observe that from the range of 4 to 6, our ideal cluster is found with a relatively low SSE and with the least number of clusters. For this analysis I ended up using four clusters.</p>
<p><img src="https://miro.medium.com/max/1400/1*VLbim6qpidRuBWZhHfYpLg.png" alt="img"></p>
<p>We can observe in a visual way how the clustering of the songs resulted. Now we want to know, what criteria did the algorithm use for each one? And what is the difference between one and the other? To corroborate this, we are going to plot the characteristics of each cluster in a polar chart.</p>
<p><img src="https://miro.medium.com/max/1400/1*YIJrgWtE6XbpiESxOblAeA.png" alt="img"></p>
<p>With the polar chart we obtain a much more visual graph to be able to understand which pattern the algorithm chose for each cluster. We quickly observe that, for example, cluster number 1 is the one with the greatest instrumentalness, therefore the songs in this cluster do not have many lyrics. On the other hand, we observe that cluster three has a greater range of acousticness, therefore the songs that compose it will be mostly acoustic.</p>
<p><img src="https://miro.medium.com/max/1256/1*C0Cf-LwM7lOH04H_4cGb2g.png" alt="img"></p>
<p>These two clusters at first glance in the graph above seem to have a lot in common, the reality is that when comparing them we see that cluster 0 has higher valence and a minimal increase in energy and danceability. At the time of practice, perhaps the songs on both playlists seem to have a lot in common.</p>
<hr>
<p>As a final conclusion of this post we can begin to understand how Spotify creates its lists at a very basic level, obviously its recommendations have a deeper level of analysis and code but to be something that we put together in a short time, the result is quite good in my opinion. opinion and you can see the patterns in the lists we generate.</p>
<p>I leave you the links of the playlists so that you can try it and give your own verdict.</p>
<p><a href="https://open.spotify.com/playlist/4ludJ86aIyt11kXCF81C49?si=7Vkgi49BSSWA-HIAGEqqzQ">Cluster 0</a></p>
<p><a href="https://open.spotify.com/playlist/54XX5WNijK2LVNNupCi8Kp?si=3EteH5GGQvKzPQNnYZMMug">Cluster 1</a></p>
<p><a href="https://open.spotify.com/playlist/4LdTX6IVtQcqGQmp0XPy5C?si=y_Zp6_4XSpCUKXZjLT34Zg">Cluster 2</a></p>
<p><a href="https://open.spotify.com/playlist/4ZE5nTjZCa2fWbZU2ogCjS?si=AsuuRlAsRtmUdClYx1pQHA">Cluster 3</a></p>
<p>Finally I leave the <a href="https://github.com/rubzk/spotify-data-analysis">link to the repository</a> in case you want to see the complete code.</p>

		</div>



	</div>



</div>

		</main>

	</div>
</body><footer class="py-6  inset-x-0 bottom-0 flex justify-center text-white p-15 bg-black">
	<div class="flex flex-col">

		<div>

			<span class="bg-white text-black font-bold p-2">copyright 2022 rubz. </span>

		</div>



		<div class="flex flex-row justify-between my-4">

			<a href="mailto:tomas.ertola@gmail.com" target="_blank">

				<svg class="h5 w-5 mr-4 transform transition-all hover:text-gray-500" fill="currentColor"
					xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024">
					<path
						d="M928 160H96c-17.7 0-32 14.3-32 32v640c0 17.7 14.3 32 32 32h832c17.7 0 32-14.3 32-32V192c0-17.7-14.3-32-32-32zm-80.8 108.9L531.7 514.4c-7.8 6.1-18.7 6.1-26.5 0L189.6 268.9A7.2 7.2 0 0 1 194 256h648.8a7.2 7.2 0 0 1 4.4 12.9z" />
				</svg>

			</a>

			<a href="https://twitter.com/theworldisdata" target="_blank">

				<svg class="h5 w-5 mr-4 transform transition-all hover:text-gray-500" xmlns="http://www.w3.org/2000/svg"
					viewBox="0 0 24 24" fill="currentColor">
					<path
						d="M23.643 4.937c-.835.37-1.732.62-2.675.733a4.67 4.67 0 0 0 2.048-2.578a9.3 9.3 0 0 1-2.958 1.13a4.66 4.66 0 0 0-7.938 4.25a13.229 13.229 0 0 1-9.602-4.868c-.4.69-.63 1.49-.63 2.342A4.66 4.66 0 0 0 3.96 9.824a4.647 4.647 0 0 1-2.11-.583v.06a4.66 4.66 0 0 0 3.737 4.568a4.692 4.692 0 0 1-2.104.08a4.661 4.661 0 0 0 4.352 3.234a9.348 9.348 0 0 1-5.786 1.995a9.5 9.5 0 0 1-1.112-.065a13.175 13.175 0 0 0 7.14 2.093c8.57 0 13.255-7.098 13.255-13.254c0-.2-.005-.402-.014-.602a9.47 9.47 0 0 0 2.323-2.41l.002-.003z" />
				</svg>
			</a>


			<a href="https://www.linkedin.com/in/tomas-ertola/" target="_blank">

				<svg class="h5 w-5 mr-4 transform transition-all hover:text-gray-500" fill="currentColor"
					xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1000 1000">
					<path
						d="M196.064.25C88.347.25.187 88.408.187 196.127v607.841c0 107.717 88.158 195.845 195.877 195.845h607.841c107.718 0 195.845-88.127 195.845-195.845V196.127C999.75 88.41 911.623.25 803.905.25H196.064zm49.266 164.948c51.648 0 83.461 33.906 84.443 78.475c0 43.585-32.797 78.444-85.442 78.444h-.969c-50.665 0-83.412-34.857-83.412-78.444c0-44.568 33.738-78.475 85.379-78.475zm445.08 208.31c99.329 0 173.79 64.922 173.79 204.436v260.449H713.247V595.406c0-61.06-21.847-102.718-76.476-102.718c-41.704 0-66.562 28.078-77.476 55.202c-3.987 9.704-4.967 23.257-4.967 36.832v253.671H403.375s1.981-411.613 0-454.233h150.984v64.324c20.06-30.95 55.942-74.977 136.051-74.977zm-521.556 10.685h150.953v454.202H168.854V384.193z">
				</svg>


			</a>

		</div>

	</div>

</footer></html>